epochs: 100
batch_size: 16
vocab_size: 25
task: nf # hemo, nf
debug: false

network:
  drp: 0.3 #0.1
  proj_dim: 256
  GNN:
    gat_heads: 8   # 对应gat1/gat2的8头
    tf_heads: 8    # 对应transformer1的8头
    gat3_heads: 4
    input_dim: 11
    hidden_dim: 512 #2048

  BERT:
    hidden_size: 256
    hidden_layers: 8
    attn_heads: 16
    dropout: 0.3 # 0.10

optim:
  lr: 5.0e-5 #6.0e-5

  weight_decay: 5e-5  # 新增L2正则
sch:
  name: lronplateau
  factor: 0.3
  patience: 3
  min_lr: 1e-6
paths:
  data: data/
  split: full/

#
#epochs: 25
#batch_size: 16
#vocab_size: 25
#task: hemo      # hemo, nf
#debug: false
#
#network:
#  drp: 0.1
#  proj_dim: 512
#  GNN:
#    input_dim: 11    # 需确认与数据特征维度一致
#    hidden_dim: 256
#  # 移除ESM配置（代码中直接加载预训练模型）
#
#optim:
#  lr: 6.0e-5        # 推荐保持原ESM预训练的学习率
#
#sch:
#  name: lronplateau
#  factor: 0.3
#  patience: 3
#  steps: 0          # 需添加steps参数（代码config['sch']['steps']）
#
#paths:
#  data: data/       # 需确保路径结尾有/
#  split: full/


